{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARPESNet compression appied to Clustering simulated nanoARPES data\n",
    "\n",
    "In this notebook we will explore an application of the compression provided by ARPESNet. We will use a simulated nanoARPES dataset, which is a 3D array of ARPES spectra, and apply ARPESNet to compress it. We will then use the compressed data to perform clustering and compare the results to clustering performed on the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import arpesnet as an\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data\n",
    "we start by loading 5 spectra from a single material. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = torch.load('../data/cluster_centers.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,len(cluster_centers),figsize=(6,3))\n",
    "\n",
    "ref = cluster_centers[2]\n",
    "for i,img in enumerate(cluster_centers):\n",
    "    # img = tr.pipe(cut.values,transform_nonoise).numpy()\n",
    "    ax[0,i].imshow(img.numpy(), cmap='viridis', interpolation='none',origin='lower',aspect='equal')\n",
    "    ax[0,i].set_title(f'{i}')\n",
    "    ax[0,i].set_xlabel('ky')\n",
    "    ax[0,i].set_ylabel('E')\n",
    "    #tu0,rn off axis\n",
    "    ax[0,i].axis('off')\n",
    "    diff = img-ref\n",
    "    ax[1,i].imshow(diff.numpy(), cmap='bwr', clim=(-100,100), interpolation='none',origin='lower',aspect='equal')\n",
    "    ax[1,i].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add poissonian noise\n",
    "We add poissonian noise to the data to simulate the noise in real ARPES data. `n_counts` is the average number of counts per spectra in the noisy data, which simulates acquiring data for shorter times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_counts = 10_000\n",
    "noiser = an.transform.SetRandomPoissonExposure(n_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,len(cluster_centers),figsize=(6,3))\n",
    "noisy = [noiser(img) for img in cluster_centers]\n",
    "ref = noisy[2]\n",
    "for i,img in enumerate(noisy):\n",
    "    ax[0,i].imshow(img.numpy(), cmap='viridis', interpolation='none',origin='lower',aspect='equal')\n",
    "    ax[0,i].set_title(f'{i}')\n",
    "    ax[0,i].set_xlabel('ky')\n",
    "    ax[0,i].set_ylabel('E')\n",
    "    #tu0,rn off axis\n",
    "    ax[0,i].axis('off')\n",
    "    diff = img-ref\n",
    "    vmax = np.max(np.abs(img.numpy()))\n",
    "    ax[1,i].set_title(f'N: {img.sum()}')\n",
    "    ax[1,i].imshow(diff.numpy(), cmap='bwr', clim=(-vmax,vmax), interpolation='none',origin='lower',aspect='equal')\n",
    "    ax[1,i].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a ground truth map\n",
    "We create a ground truth map for the data, which will be used to evaluate the clustering results. The ground truth map is a 2D array with the same shape as the data, where each pixel has a unique integer value. The pixels with the same value belong to the same cluster. Then, we assign spectra with random noise to each pixel, so that the spectra in the same cluster (of the ground truth map) originate from the same spectrum, but have different noise patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros((50,50))\n",
    "arr[:,:10] = 0\n",
    "arr[:,10:20] = 1\n",
    "arr[:,20:30] = 2\n",
    "arr[:,30:40] = 3\n",
    "arr[:,40:] = 4\n",
    "arr = arr.T\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(arr,cmap=\"RdBu\", interpolation='none')\n",
    "ground_truth = arr.astype(np.int64)\n",
    "n_clusters = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign spectra to each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatmap = []\n",
    "for i in tqdm(\n",
    "    ground_truth.ravel(),\n",
    "    total=len(ground_truth.ravel()),\n",
    "    desc=\"generate noisy map\",\n",
    "):\n",
    "    flatmap.append(noiser(cluster_centers[i]))\n",
    "flatmap = torch.stack(flatmap).to(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "intensity_map = flatmap.sum((1,2)).reshape(50,50)\n",
    "plt.imshow(intensity_map,cmap='RdBu',interpolation='none')\n",
    "print(intensity_map.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARPESNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load trained model\n",
    "We load a pre-trained ARPESNet model. The model was trained on a dataset of ARPES spectra from various materials. The model is a convolutional autoencoder, which compresses the input spectra into a lower-dimensional representation and then reconstructs the input spectra from the compressed representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpesnet = an.load_trainer(\"../trained_model/arpesnet_n2n_4k.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test reconstruction of noisy data\n",
    "We test the reconstruction of the noisy data by passing it through the ARPESNet model. We compare the original noisy data with the reconstructed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,len(cluster_centers),figsize=(6,3))\n",
    "noisy = [noiser(img) for img in cluster_centers]\n",
    "reconstructed = [arpesnet.eval(img) for img in noisy]\n",
    "ref = reconstructed[2]\n",
    "for i, img, rec in zip(range(len(noisy)), noisy, reconstructed):\n",
    "    ax[0,i].imshow(img.numpy(), cmap='viridis', interpolation='none',origin='lower',aspect='equal')\n",
    "    ax[0,i].set_title(f'{i}')\n",
    "    ax[0,i].set_xlabel('ky')\n",
    "    ax[0,i].set_ylabel('E')\n",
    "    #tu0,rn off axis\n",
    "    ax[0,i].axis('off')\n",
    "    ax[1,i].imshow(rec.numpy(), cmap='viridis', interpolation='none',origin='lower',aspect='equal')\n",
    "    ax[1,i].axis('off')\n",
    "    diff = rec-ref\n",
    "    vmax = np.max(np.abs(img.numpy()))\n",
    "    ax[2,i].imshow(diff.numpy(), cmap='bwr', clim=(-vmax,vmax), interpolation='none',origin='lower',aspect='equal')\n",
    "    ax[2,i].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode the noisy map data\n",
    "To prepare for clustering, we encode the noisy map data using the ARPESNet model. We pass the noisy map data through the encoder part of the ARPESNet model to obtain the compressed representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = torch.stack([arpesnet.encode(img).cpu().detach().squeeze().flatten() for img in flatmap])\n",
    "encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering\n",
    "We perform clustering on the compressed data using k-means clustering. We choose the number of clusters to be the same as the number of clusters in the ground truth map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def remap_labels(pred_labels, true_labels) -> tuple:\n",
    "    \"\"\"Rename prediction labels (clustered output) to best match true labels.\"\"\"\n",
    "    pred_labels, true_labels = np.array(pred_labels), np.array(true_labels)\n",
    "    assert pred_labels.ndim == 1 == true_labels.ndim\n",
    "    assert len(pred_labels) == len(true_labels)\n",
    "    cluster_names = np.unique(pred_labels)\n",
    "    accuracy = 0\n",
    "\n",
    "    perms = np.array(list(permutations(np.unique(true_labels))))\n",
    "\n",
    "    remapped_labels = true_labels\n",
    "    for perm in perms:\n",
    "        flipped_labels = np.zeros(len(true_labels))\n",
    "        for label_index, label in enumerate(cluster_names):\n",
    "            flipped_labels[pred_labels == label] = perm[label_index]\n",
    "\n",
    "        testAcc = np.sum(flipped_labels == true_labels) / len(true_labels)\n",
    "        if testAcc > accuracy:\n",
    "            accuracy = testAcc\n",
    "            remapped_labels = flipped_labels\n",
    "\n",
    "    return accuracy, remapped_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute kmeans\n",
    "We compute k-means clustering on the compressed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=n_clusters, n_init=100)\n",
    "result =  km.fit(encoded)\n",
    "sorted_labels = remap_labels(result.labels_, ground_truth.ravel())[1].reshape(50,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(5,3))\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "ax[0].imshow(ground_truth, cmap='RdBu', interpolation='none')\n",
    "ax[0].set_title('ground truth')\n",
    "ax[1].imshow(sorted_labels, cmap='RdBu', interpolation='none')\n",
    "ax[1].set_title('clsutering result')\n",
    "accuracy = np.sum(ground_truth == sorted_labels) / (50*50)\n",
    "plt.suptitle(f'clustering with {n_counts:,.0f} counts | Accuracy={accuracy:.2%}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clusering uncompressed data\n",
    "Let's now compare with clustering of uncompressed data. This will take longer to run, about a few minutes depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_raw = km.fit(flatmap.view(50*50,-1).cpu().numpy())\n",
    "sorted_labels_raw = remap_labels(result_raw.labels_, ground_truth.ravel())[1].reshape(50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(10,4))\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "ax[0].imshow(ground_truth, cmap='RdBu', interpolation='none')\n",
    "ax[0].set_title('ground truth')\n",
    "ax[1].imshow(sorted_labels_raw, cmap='RdBu', interpolation='none')\n",
    "ax[1].set_title(f'raw: {np.sum(ground_truth == sorted_labels_raw) / (50*50)}')\n",
    "ax[2].imshow(sorted_labels, cmap='RdBu', interpolation='none')\n",
    "ax[2].set_title(f'ARPESNet: {np.sum(ground_truth == sorted_labels) / (50*50)}')\n",
    "\n",
    "accuracy = np.sum(ground_truth == sorted_labels) / (50*50)\n",
    "plt.suptitle(f'clustering with {n_counts:,.0f} counts');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arpesnet-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
